# -*- coding: utf-8 -*-
"""dissertation_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fLb2W9ch8JHZCImMrH7aQP7v90GDoAw8

Title:
Enhancing Vehicle Identification Systems: A Deep Learning Approach to Detecting
Cloned and Anomalous License Plates in the UK

This script is my end-to-end experimental pipeline. It covers:

1. Uploading my datasets into the Colab environment:
   - Original vehicle images (dataset/images/)
   - Pascal VOC XML annotations (dataset/annotations/)
   - Synthetic UK licence plate crops (synthetic_plates/)
   - Trained YOLOv8 model for plate detection (license_plate_best.pt)

2. Generating a synthetic cloned dataset by overlaying the same UK-style
   plate images onto multiple vehicles to create "clone" scenarios.

3. Running an ANPR-like pipeline:
   - YOLOv8 for licence plate detection
   - EasyOCR for plate text extraction and confidence
   - ResNet50 embeddings (ReID) for vehicle appearance similarity

4. Adding a simple temporal–spatial anomaly module using synthetic
   locations and timestamps, to approximate impossible travel speeds.

5. Fusing visual, OCR, and temporal cues into clone suspicion scores.

6. Evaluating the system using my synthetic setup as ground truth, and
   performing ablation (OCR-only vs ReID-only vs Fusion).
"""

!pip install ultralytics easyocr opencv-python-headless torch torchvision scikit-learn pandas matplotlib

# importing libraries

import os
import csv
import random
import xml.etree.ElementTree as ET
import re
from math import radians, sin, cos, sqrt, atan2
from collections import defaultdict

import cv2
import numpy as np
import torch
import torchvision.transforms as T
from torchvision.models import resnet50, ResNet50_Weights
from ultralytics import YOLO
import easyocr
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
    precision_recall_curve
)
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import files
import shutil

# I fix the random seeds so that the synthetic parts are reproducible.
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

plt.rcParams["figure.figsize"] = (6, 5)

"""2. DIRECTORY STRUCTURE"""

# I organise the project in a simple folder structure.
os.makedirs("dataset/images", exist_ok=True)
os.makedirs("dataset/annotations", exist_ok=True)
os.makedirs("synthetic_plates", exist_ok=True)
os.makedirs("cloned_images", exist_ok=True)

DATASET_ROOT = "dataset"
IMAGES_DIR = os.path.join(DATASET_ROOT, "images")
ANN_DIR = os.path.join(DATASET_ROOT, "annotations")
SYNTH_PLATE_DIR = "synthetic_plates"
OUT_IMG_DIR = "cloned_images"
META_CSV = "cloned_metadata.csv"   # mapping original ↔ cloned ↔ synthetic plate

print("Base folders ready:")
print(" -", IMAGES_DIR)
print(" -", ANN_DIR)
print(" -", SYNTH_PLATE_DIR)
print(" -", OUT_IMG_DIR)

"""3. UPLOAD DATASETS INTO COLAB


  In this section, I upload:
   1) Synthetic UK-style plate crops
   2) Original vehicle images
   3) Pascal VOC XML annotations
   4) My trained YOLOv8 model weights (license_plate_best.pt)

"""

# 3.1 Upload synthetic plate crops
print("\n Step 1: Upload SYNTHETIC UK PLATE IMAGES (PNG/JPG)...")
print("Please select all synthetic plate crops (e.g. AA11BBB.png, etc.)")
uploaded_plates = files.upload()

for fname in uploaded_plates.keys():
    src = fname
    dst = os.path.join(SYNTH_PLATE_DIR, fname)
    shutil.move(src, dst)

print("Moved synthetic plates to", SYNTH_PLATE_DIR)
print("Synthetic plates:", os.listdir(SYNTH_PLATE_DIR))

# 3.2 Upload vehicle images
print("\n Step 2: Upload VEHICLE IMAGES (JPG/PNG)...")
print("Please select all vehicle images.")
uploaded_images = files.upload()

for fname in uploaded_images.keys():
    src = fname
    dst = os.path.join(IMAGES_DIR, fname)
    shutil.move(src, dst)

print(" Moved vehicle images to", IMAGES_DIR)
print("Example images:", os.listdir(IMAGES_DIR)[:10])

# 3.3 Upload XML annotations
print("\n Step 3: Upload XML ANNOTATIONS (Pascal VOC)...")
print("Please select all .xml annotation files.")
uploaded_xml = files.upload()

for fname in uploaded_xml.keys():
    src = fname
    dst = os.path.join(ANN_DIR, fname)
    shutil.move(src, dst)

print(" Moved XML files to", ANN_DIR)
print("Example XMLs:", os.listdir(ANN_DIR)[:10])

# 3.4 Upload YOLOv8 weight file (license_plate_best.pt)
print("\n Step 4: Upload YOLOv8 WEIGHTS (license_plate_best.pt)...")
print("Please select  trained licence plate detection model file.")
uploaded_yolo = files.upload()

if "license_plate_best.pt" not in uploaded_yolo:
    print(" Warning: I expected 'license_plate_best.pt'. "
          "If you used a different name, update YOLO_MODEL_PATH below.")
else:
    print(" YOLO weights uploaded.")

print("\nCurrent folder status:")
print("Images in dataset/images:", len(os.listdir(IMAGES_DIR)))
print("XMLs in dataset/annotations:", len(os.listdir(ANN_DIR)))
print("Synthetic plates in synthetic_plates:", len(os.listdir(SYNTH_PLATE_DIR)))

"""4. HELPER: LOAD PLATE/OBJECT BBOX FROM PASCAL VOC XML

"""

def load_plate_bbox(xml_path):
    """
    Read a Pascal VOC XML file and return:
      - the corresponding image filename
      - a bounding box (xmin, ymin, xmax, ymax)

    I first try to find an object whose <name> contains 'license'/'licence'/'plate'.
    If none is found, I fall back to the first <object> (useful if the dataset
    only labels 'Car' or 'Vehicle').
    """
    tree = ET.parse(xml_path)
    root = tree.getroot()

    filename_tag = root.find("filename")
    if filename_tag is None:
        return None, None
    filename = filename_tag.text

    objs = root.findall("object")
    if not objs:
        return filename, None

    plate_obj = None
    for o in objs:
        name_tag = o.find("name")
        if name_tag is None:
            continue
        name = name_tag.text.lower()
        if "license" in name or "licence" in name or "plate" in name:
            plate_obj = o
            break

    # If I cannot specifically find a plate, I fall back to the first object
    if plate_obj is None:
        plate_obj = objs[0]

    bbox = plate_obj.find("bndbox")
    if bbox is None:
        return filename, None

    try:
        xmin = int(bbox.find("xmin").text)
        ymin = int(bbox.find("ymin").text)
        xmax = int(bbox.find("xmax").text)
        ymax = int(bbox.find("ymax").text)
    except Exception as e:
        print(f"[WARN] Bad bbox in {xml_path}: {e}")
        return filename, None

    return filename, (xmin, ymin, xmax, ymax)

"""5. HELPER: OVERLAY SYNTHETIC PLATE ON VEHICLE"""

def overlay_plate(vehicle_img, plate_img, bbox):
    """
    Overlays a synthetic plate image onto the vehicle at the given bounding box.

    vehicle_img: BGR vehicle image from cv2
    plate_img:   BGR plate crop
    bbox:        (xmin, ymin, xmax, ymax)
    """
    xmin, ymin, xmax, ymax = bbox
    w = xmax - xmin
    h = ymax - ymin

    plate_resized = cv2.resize(plate_img, (w, h))
    vehicle_img[ymin:ymax, xmin:xmax] = plate_resized
    return vehicle_img

"""6. GENERATE CLONED DATASET (SAME PLATE ON MULTIPLE VEHICLES)"""

metadata_rows = []

xml_files = [f for f in os.listdir(ANN_DIR) if f.endswith(".xml")]
print("\nXML annotation files found:", len(xml_files))

synthetic_plates_paths = [
    os.path.join(SYNTH_PLATE_DIR, f)
    for f in os.listdir(SYNTH_PLATE_DIR)
    if f.lower().endswith((".png", ".jpg", ".jpeg"))
]
print("Synthetic plates found:", len(synthetic_plates_paths))
print("Example synthetic plates:", [os.path.basename(p) for p in synthetic_plates_paths[:5]])

if len(synthetic_plates_paths) == 0:
    print(" No synthetic plates available. I cannot create clones without them.")
    shared_synth_plates = []
else:
    # I deliberately reuse a small number of synthetic plates so the same
    # plate appears on multiple different vehicles (clone scenarios).
    n_shared = min(5, len(synthetic_plates_paths))
    shared_synth_plates = synthetic_plates_paths[:n_shared]
    print("Using these plates for cloning:", [os.path.basename(p) for p in shared_synth_plates])

clone_count = 0
skipped_no_bbox = 0
skipped_no_img = 0

for idx, xml_name in enumerate(xml_files):
    xml_path = os.path.join(ANN_DIR, xml_name)
    img_name, bbox = load_plate_bbox(xml_path)

    if bbox is None:
        skipped_no_bbox += 1
        continue

    img_path = os.path.join(IMAGES_DIR, img_name)
    vehicle = cv2.imread(img_path)
    if vehicle is None:
        skipped_no_img += 1
        continue

    if not shared_synth_plates:
        continue

    synth_path = shared_synth_plates[idx % len(shared_synth_plates)]
    synth_plate = cv2.imread(synth_path)
    if synth_plate is None:
        print(f"[WARN] Could not read synthetic plate: {synth_path}")
        continue

    cloned_img = overlay_plate(vehicle.copy(), synth_plate, bbox)

    base, ext = os.path.splitext(img_name)
    out_name = f"{base}_clone{ext}"
    out_path = os.path.join(OUT_IMG_DIR, out_name)
    cv2.imwrite(out_path, cloned_img)
    clone_count += 1

    metadata_rows.append({
        "original": img_name,
        "cloned": out_name,
        "synthetic_plate": os.path.basename(synth_path)
    })

print(f"\nSummary of cloning:")
print(f" - Created {clone_count} cloned images.")
print(f" - Skipped {skipped_no_bbox} images (no bbox).")
print(f" - Skipped {skipped_no_img} images (missing original).")

if metadata_rows:
    with open(META_CSV, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["original", "cloned", "synthetic_plate"])
        writer.writeheader()
        writer.writerows(metadata_rows)
    print(f" Metadata saved to '{META_CSV}' with {len(metadata_rows)} rows.")
else:
    print(" No cloned images were created. I need to check dataset/annotations and synthetic plates.")

# Quick visual sanity check
if metadata_rows:
    example = metadata_rows[0]
    orig_path = os.path.join(IMAGES_DIR, example["original"])
    clone_path = os.path.join(OUT_IMG_DIR, example["cloned"])

    orig_img = cv2.imread(orig_path)
    clone_img = cv2.imread(clone_path)

    if orig_img is not None and clone_img is not None:
        orig_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)
        clone_rgb = cv2.cvtColor(clone_img, cv2.COLOR_BGR2RGB)

        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.title("Original")
        plt.imshow(orig_rgb)
        plt.axis("off")

        plt.subplot(1, 2, 2)
        plt.title(f"Cloned ({example['synthetic_plate']})")
        plt.imshow(clone_rgb)
        plt.axis("off")
        plt.show()
    else:
        print(" Could not load example images for visualisation.")

"""7. LOAD MODELS (YOLO FOR PLATE, EASYOCR, RESNET FOR REID)"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("\nUsing device:", device)

YOLO_MODEL_PATH = "license_plate_best.pt"  # uploaded above
if not os.path.exists(YOLO_MODEL_PATH):
    print(f" '{YOLO_MODEL_PATH}' not found. Please check the upload step.")
yolo_model = YOLO(YOLO_MODEL_PATH)
PLATE_CLASS_ID = 0  # I assume a single class = licence plate

ocr_reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())

weights = ResNet50_Weights.DEFAULT
resnet = resnet50(weights=weights).to(device)
resnet.eval()
feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])

embed_transform = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225])
])

"""8. HELPER FUNCTIONS: OCR CLEANING, EMBEDDINGS, TEMPORAL UTILS"""

def clean_plate_text(raw_text):
    """
    I cleaned up the raw OCR text so it looks more like a registration:
    - upper case
    - no spaces
    - A–Z and 0–9 only
    """
    raw_text = raw_text.upper()
    raw_text = raw_text.replace(" ", "")
    cleaned = re.sub(r"[^A-Z0-9]", "", raw_text)
    return cleaned

def get_vehicle_embedding(img_bgr):
    """
    Compute a L2-normalised appearance embedding using ResNet50 features.
    For this project, I use the full image as a proxy for the vehicle region.
    """
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)

    x = embed_transform(pil_img).unsqueeze(0).to(device)
    with torch.no_grad():
        feat = feature_extractor(x)  # (1, 2048, 1, 1)
    vec = feat.view(feat.size(0), -1).cpu().numpy()[0]

    norm = np.linalg.norm(vec)
    if norm > 0:
        vec = vec / norm
    return vec

def generate_random_location_uk():
    """
    Generate a synthetic lat/lon roughly within the UK.
    This is used to simulate plate sightings in different places.
    """
    lat = random.uniform(50.0, 55.8)
    lon = random.uniform(-5.5, 1.5)
    return lat, lon

def generate_random_time_minutes():
    """
    Generate a synthetic time of day in minutes since midnight.
    """
    return random.uniform(0, 1440)

def haversine_km(lat1, lon1, lat2, lon2):
    """
    Great-circle distance between two lat/lon points in kilometres.
    """
    R = 6371.0
    phi1 = radians(lat1)
    phi2 = radians(lat2)
    dphi = radians(lat2 - lat1)
    dlambda = radians(lon2 - lon1)

    a = sin(dphi / 2) ** 2 + cos(phi1) * cos(phi2) * sin(dlambda / 2) ** 2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c

def temporal_anomaly_score(rec_i, rec_j,
                           speed_limit=130.0,
                           max_speed=400.0):
    """
    Compute a temporal anomaly score based on implied travel speed (km/h).

    - rec_i, rec_j each contain (lat, lon, time_min)
    - If the implied speed is below 'speed_limit', score = 0
    - If the implied speed is above 'max_speed', score = 1
    - Between the two, I scale linearly.

    This is a simple way to approximate impossible plate movements.
    """
    lat1, lon1, t1 = rec_i["lat"], rec_i["lon"], rec_i["time_min"]
    lat2, lon2, t2 = rec_j["lat"], rec_j["lon"], rec_j["time_min"]

    dt_min = abs(t2 - t1)
    dt_hours = dt_min / 60.0
    if dt_hours < 1e-3:
        return 0.0

    dist_km = haversine_km(lat1, lon1, lat2, lon2)
    speed = dist_km / dt_hours

    if speed <= speed_limit:
        return 0.0
    elif speed >= max_speed:
        return 1.0
    else:
        return (speed - speed_limit) / (max_speed - speed_limit)

"""9. PROCESS A SINGLE IMAGE (YOLO + OCR + EMBEDDING + TEMPORAL META)"""

def process_image(image_path, conf_thresh=0.25):
    """
    Run the full perception pipeline on a single image:

    1) Licence plate detection with YOLOv8
    2) OCR with EasyOCR on a cropped plate region
    3) Vehicle appearance embedding using ResNet50
    4) Synthetic spatio-temporal metadata (lat, lon, time_min)

    Returns a record dict or None if nothing usable is found.
    """
    img = cv2.imread(image_path)
    if img is None:
        print(f"[WARN] could not read {image_path}")
        return None

    # 1) YOLO plate detection
    results = yolo_model(img)[0]
    if results.boxes is None or len(results.boxes) == 0:
        return None

    boxes = results.boxes
    cls = boxes.cls.cpu().numpy().astype(int)
    conf = boxes.conf.cpu().numpy()

    plate_indices = [i for i, c in enumerate(cls) if c == PLATE_CLASS_ID and conf[i] >= conf_thresh]
    if not plate_indices:
        return None

    best_idx = plate_indices[np.argmax([conf[i] for i in plate_indices])]
    x1, y1, x2, y2 = boxes.xyxy[best_idx].cpu().numpy().astype(int)
    plate_conf = float(conf[best_idx])

    h, w = img.shape[:2]
    x1 = max(0, min(x1, w - 1))
    x2 = max(0, min(x2, w))
    y1 = max(0, min(y1, h - 1))
    y2 = max(0, min(y2, h))

    plate_crop = img[y1:y2, x1:x2]
    if plate_crop.size == 0:
        return None

    # 2) OCR on central region of the plate
    ph, pw = plate_crop.shape[:2]
    x_start = int(0.1 * pw)
    x_end = int(0.9 * pw)
    central_crop = plate_crop[:, x_start:x_end]

    ocr_result = ocr_reader.readtext(central_crop)
    if len(ocr_result) == 0:
        return None

    best_ocr = max(ocr_result, key=lambda x: x[2])
    plate_text_raw = best_ocr[1]
    ocr_conf = float(best_ocr[2])
    plate_text = clean_plate_text(plate_text_raw)

    if len(plate_text) < 4:
        return None

    # 3) Vehicle embedding
    embedding = get_vehicle_embedding(img)

    # 4) Synthetic spatio-temporal metadata
    lat, lon = generate_random_location_uk()
    t_min = generate_random_time_minutes()

    # Identify the source directory
    if image_path.startswith(OUT_IMG_DIR):
        source_dir = "cloned_images"
    elif image_path.startswith(IMAGES_DIR):
        source_dir = "dataset/images"
    else:
        source_dir = "other"

    return {
        "plate_text": plate_text,
        "ocr_conf": ocr_conf,
        "embedding": embedding,
        "image_path": image_path,
        "plate_bbox": (int(x1), int(y1), int(x2), int(y2)),
        "yolo_conf": plate_conf,
        "lat": lat,
        "lon": lon,
        "time_min": t_min,
        "source_dir": source_dir
    }

"""10. PROCESS ALL IMAGES IN ORIGINAL + CLONED DIRECTORIES"""

IMAGE_DIRS = [IMAGES_DIR, OUT_IMG_DIR]
records = []

for d in IMAGE_DIRS:
    if not os.path.isdir(d):
        continue

    print(f"\nProcessing directory: {d}")
    for fname in os.listdir(d):
        if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
            continue
        path = os.path.join(d, fname)
        rec = process_image(path, conf_thresh=0.25)
        if rec is not None:
            records.append(rec)

print("\nTotal processed records:", len(records))
print("From originals:", sum(r["source_dir"] == "dataset/images" for r in records))
print("From cloned images:", sum(r["source_dir"] == "cloned_images" for r in records))

# Group by recognised plate text
groups = defaultdict(list)
for rec in records:
    groups[rec["plate_text"]].append(rec)

print("\nUnique plates seen:", len(groups))
print("Example group sizes (first 10):")
for p, g in list(groups.items())[:10]:
    print(p, "→", len(g), "sightings")

def pairwise_clone_candidates(group, sim_threshold=0.75):
    """
    For a list of records with the same plate_text, compute cosine similarity
    between embeddings and keep pairs that look like different vehicles.
    """
    suspicious_pairs = []
    n = len(group)
    if n < 2:
        return suspicious_pairs

    embs = np.stack([g["embedding"] for g in group], axis=0)
    sims = cosine_similarity(embs)

    for i in range(n):
        for j in range(i + 1, n):
            sim = float(sims[i, j])
            if sim < sim_threshold:
                suspicious_pairs.append({
                    "plate_text": group[0]["plate_text"],
                    "record_i": group[i],
                    "record_j": group[j],
                    "similarity": sim
                })
    return suspicious_pairs

"""11. FUSION SCORING: VISUAL + OCR + TEMPORAL"""

all_suspicions = []

SIM_THRESHOLD = 0.75
ALPHA_VISUAL = 0.6
BETA_OCR = 0.2
GAMMA_TEMPORAL = 0.2

for plate, group in groups.items():
    if len(group) < 2:
        continue

    suspicious_pairs = pairwise_clone_candidates(group, sim_threshold=SIM_THRESHOLD)
    for pair in suspicious_pairs:
        rec_i = pair["record_i"]
        rec_j = pair["record_j"]
        sim = pair["similarity"]

        # Visual difference term
        visual_term = 1.0 - sim

        # OCR uncertainty term
        min_ocr_conf = min(rec_i["ocr_conf"], rec_j["ocr_conf"])
        ocr_uncertainty = 1.0 - min_ocr_conf

        # Baseline 2-modal score (visual + OCR)
        clone_score_2mod = 0.7 * visual_term + 0.3 * ocr_uncertainty
        clone_score_2mod = float(max(0.0, min(1.0, clone_score_2mod)))
        pair["clone_score"] = clone_score_2mod

        # Temporal anomaly score
        temp_score = temporal_anomaly_score(rec_i, rec_j)
        pair["temporal_score"] = temp_score

        # 3-modal fusion score
        clone_score_full = (
            ALPHA_VISUAL * visual_term +
            BETA_OCR * ocr_uncertainty +
            GAMMA_TEMPORAL * temp_score
        )
        clone_score_full = float(max(0.0, min(1.0, clone_score_full)))
        pair["clone_score_full"] = clone_score_full

        all_suspicions.append(pair)

print("\nTotal suspicious pairs with temporal scoring:", len(all_suspicions))

# Build clone_df with all scores and metadata
rows = []
for p in all_suspicions:
    rec_i = p["record_i"]
    rec_j = p["record_j"]
    rows.append({
        "plate_text": p["plate_text"],
        "image_a": rec_i["image_path"],
        "image_b": rec_j["image_path"],
        "similarity": p["similarity"],
        "ocr_conf_a": rec_i["ocr_conf"],
        "ocr_conf_b": rec_j["ocr_conf"],
        "clone_score": p["clone_score"],          # visual + OCR
        "temporal_score": p["temporal_score"],
        "clone_score_full": p["clone_score_full"],
        "lat_a": rec_i["lat"],
        "lon_a": rec_i["lon"],
        "time_min_a": rec_i["time_min"],
        "lat_b": rec_j["lat"],
        "lon_b": rec_j["lon"],
        "time_min_b": rec_j["time_min"],
        "source_a": rec_i["source_dir"],
        "source_b": rec_j["source_dir"],
    })

clone_df = pd.DataFrame(rows)
print("clone_df shape:", clone_df.shape)
print("clone_df columns:", list(clone_df.columns))

# Save per-plate summary
if not clone_df.empty:
    summary_df = (
        clone_df
        .groupby("plate_text")
        .agg(
            n_pairs=("clone_score", "count"),
            mean_clone_score=("clone_score", "mean"),
            max_clone_score=("clone_score", "max")
        )
        .reset_index()
        .sort_values("max_clone_score", ascending=False)
    )

    print("\nTop suspicious plates:")
    print(summary_df.head())

    clone_df.to_csv("clone_pairs_detailed.csv", index=False)
    summary_df.to_csv("clone_scores_per_plate.csv", index=False)
    print(" Saved 'clone_pairs_detailed.csv' and 'clone_scores_per_plate.csv'.")
else:
    print(" No suspicious clone pairs to summarise or save.")

"""12. VISUALISE SOME SUSPICIOUS PAIRS"""

def show_clone_pair(row_index):
    """
    Display image_a and image_b side-by-side with key details.
    """
    if clone_df is None or clone_df.empty:
        print(" No results to display.")
        return

    if row_index >= len(clone_df):
        print(" Index out of range.")
        return

    row = clone_df.iloc[row_index]
    img_a_path = row["image_a"]
    img_b_path = row["image_b"]

    img_a = cv2.imread(img_a_path)
    img_b = cv2.imread(img_b_path)

    if img_a is None or img_b is None:
        print(f" Could not load one of the images:\n{img_a_path}\n{img_b_path}")
        return

    img_a = cv2.cvtColor(img_a, cv2.COLOR_BGR2RGB)
    img_b = cv2.cvtColor(img_b, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(img_a)
    plt.title(f"Image A\n{row['image_a']}")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(img_b)
    plt.title(f"Image B\n{row['image_b']}")
    plt.axis("off")

    plt.suptitle(
        f"Plate: {row['plate_text']} | Sim: {row['similarity']:.3f} "
        f"| CloneScore: {row['clone_score']:.3f}",
        fontsize=14
    )
    plt.show()


if not clone_df.empty:
    for i in range(min(5, len(clone_df))):
        print(f"\n=== Suspicious Pair #{i} ===")
        show_clone_pair(i)
else:
    print(" No suspicious pairs to visualise.")

"""13. EVALUATION: USE SYNTHETIC METADATA AS GROUND TRUTH"""

print("\n=== EVALUATION SECTION (using visual+OCR clone_score) ===")

if not os.path.exists(META_CSV):
    print(f"⚠️ Cannot evaluate: metadata file '{META_CSV}' not found.")
elif clone_df.empty:
    print("⚠️ clone_df is empty – no suspicious pairs to evaluate.")
else:
    meta_df = pd.read_csv(META_CSV)
    meta_df["cloned_path"] = OUT_IMG_DIR + "/" + meta_df["cloned"]

    cloned_to_synth = dict(zip(meta_df["cloned_path"], meta_df["synthetic_plate"]))
    cloned_to_orig = dict(zip(meta_df["cloned_path"], meta_df["original"]))

    def label_pair(row):
        """
        True clone if:
        - both images are cloned images
        - they share the same synthetic plate
        - they come from different original vehicles
        """
        a = row["image_a"]
        b = row["image_b"]

        sa = cloned_to_synth.get(a)
        sb = cloned_to_synth.get(b)
        oa = cloned_to_orig.get(a)
        ob = cloned_to_orig.get(b)

        if (sa is not None) and (sb is not None) and (sa == sb) and (oa != ob):
            return 1
        else:
            return 0

    clone_df["is_clone_gt"] = clone_df.apply(label_pair, axis=1)
    print("Ground-truth label counts:")
    print(clone_df["is_clone_gt"].value_counts())

    if clone_df["is_clone_gt"].nunique() < 2:
        print("⚠️ Only one class present in ground truth. Metrics will be limited.")
    else:
        y_true = clone_df["is_clone_gt"].values
        y_scores = clone_df["clone_score"].values  # 2-modal score
        DEFAULT_THRESH = 0.5
        y_pred = (y_scores >= DEFAULT_THRESH).astype(int)

        cm = confusion_matrix(y_true, y_pred)
        print(f"\nConfusion matrix (threshold={DEFAULT_THRESH}):")
        print(cm)

        print("\nClassification report:")
        print(classification_report(y_true, y_pred, digits=3))

        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        print(f"ROC AUC (visual+OCR): {roc_auc:.3f}")

        plt.figure()
        plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
        plt.plot([0, 1], [0, 1], linestyle="--", color="grey")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title("ROC Curve – Clone Score (Visual + OCR)")
        plt.legend()
        plt.grid(True)
        plt.show()

"""14. ABLATION STUDY: OCR-only vs ReID-only vs Visual+OCR"""

print("\n=== ABLATION STUDY SECTION ===")

if clone_df.empty or "is_clone_gt" not in clone_df.columns:
    print(" Cannot run ablation: clone_df empty or ground-truth labels missing.")
else:
    y_true = clone_df["is_clone_gt"].values

    if clone_df["is_clone_gt"].nunique() < 2:
        print(" Ground truth has only one class. Ablation metrics are not meaningful.")
    else:
        # Define different score variants
        ocr_min_conf = np.minimum(clone_df["ocr_conf_a"].values,
                                  clone_df["ocr_conf_b"].values)
        scores_ocr_only = 1.0 - ocr_min_conf               # high if OCR is uncertain
        scores_reid_only = 1.0 - clone_df["similarity"].values
        scores_full = clone_df["clone_score"].values       # visual + OCR

        def eval_variant(y_true, scores, name, thresh=0.5):
            y_pred = (scores >= thresh).astype(int)
            print(f"\n--- {name} ---")
            cm = confusion_matrix(y_true, y_pred)
            print(f"Confusion matrix (threshold={thresh}):")
            print(cm)
            print("Classification report:")
            print(classification_report(y_true, y_pred, digits=3))
            fpr, tpr, _ = roc_curve(y_true, scores)
            roc_auc = auc(fpr, tpr)
            print(f"ROC AUC ({name}): {roc_auc:.3f}")
            return {"name": name, "cm": cm, "auc": roc_auc}

        DEFAULT_THRESH = 0.5
        res_ocr = eval_variant(y_true, scores_ocr_only, "OCR-only", DEFAULT_THRESH)
        res_reid = eval_variant(y_true, scores_reid_only, "ReID-only", DEFAULT_THRESH)
        res_full = eval_variant(y_true, scores_full, "Visual+OCR", DEFAULT_THRESH)

        # Plot ROC curves
        fpr_ocr, tpr_ocr, _ = roc_curve(y_true, scores_ocr_only)
        fpr_reid, tpr_reid, _ = roc_curve(y_true, scores_reid_only)
        fpr_full, tpr_full, _ = roc_curve(y_true, scores_full)

        plt.figure()
        plt.plot(fpr_ocr, tpr_ocr, label=f"OCR-only (AUC={res_ocr['auc']:.3f})")
        plt.plot(fpr_reid, tpr_reid, label=f"ReID-only (AUC={res_reid['auc']:.3f})")
        plt.plot(fpr_full, tpr_full, label=f"Visual+OCR (AUC={res_full['auc']:.3f})", linewidth=2)
        plt.plot([0, 1], [0, 1], linestyle="--", color="grey")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title("Ablation ROC Curves")
        plt.legend(loc="lower right")
        plt.grid(True)
        plt.show()

        # Summarise into a small table I can copy into the dissertation
        def cm_to_stats(res):
            cm = res["cm"]
            auc_val = res["auc"]
            tn, fp, fn, tp = cm.ravel()
            precision = tp / (tp + fp + 1e-9)
            recall = tp / (tp + fn + 1e-9)
            f1 = 2 * precision * recall / (precision + recall + 1e-9)
            return {
                "Variant": res["name"],
                "ROC_AUC": round(auc_val, 3),
                "Precision": round(precision, 3),
                "Recall": round(recall, 3),
                "F1_score": round(f1, 3),
                "TP": int(tp),
                "FP": int(fp),
                "FN": int(fn),
                "TN": int(tn)
            }

        ablation_df = pd.DataFrame([
            cm_to_stats(res_ocr),
            cm_to_stats(res_reid),
            cm_to_stats(res_full),
        ])
        print("\nAblation summary:")
        print(ablation_df)
        ablation_df.to_csv("ablation_summary.csv", index=False)
        print(" Saved 'ablation_summary.csv'.")

print("\nPipeline finished.")

