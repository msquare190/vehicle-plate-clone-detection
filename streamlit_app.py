# -*- coding: utf-8 -*-
"""streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lb61qQtPvD5LO-28ER1GU23xji8iF2XM
"""

import streamlit as st
import os
import re
import random
from math import radians, sin, cos, sqrt, atan2

import cv2
import numpy as np
from PIL import Image

import torch
import torchvision.transforms as T
from torchvision.models import resnet50, ResNet50_Weights
from ultralytics import YOLO
import easyocr
from sklearn.metrics.pairwise import cosine_similarity


# 1. CONFIG & GLOBALS

st.set_page_config(
    page_title="ANPR Clone Detection Demo",
    layout="wide"
)

random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

YOLO_MODEL_PATH = "license_plate_best.pt"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# 2. HELPER FUNCTIONS

def clean_plate_text(raw_text: str) -> str:
    raw_text = raw_text.upper().replace(" ", "")
    return re.sub(r"[^A-Z0-9]", "", raw_text)


def generate_random_location_uk():
    lat = random.uniform(50.0, 55.8)
    lon = random.uniform(-5.5, 1.5)
    return lat, lon


def generate_random_time_minutes():
    return random.uniform(0, 1440)


def haversine_km(lat1, lon1, lat2, lon2):
    R = 6371.0
    phi1 = radians(lat1)
    phi2 = radians(lat2)
    dphi = radians(lat2 - lat1)
    dlambda = radians(lon2 - lon1)
    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    return R * c


def temporal_anomaly_score(meta1, meta2,
                           speed_limit=130.0,
                           max_speed=400.0):
    lat1, lon1, t1 = meta1["lat"], meta1["lon"], meta1["time_min"]
    lat2, lon2, t2 = meta2["lat"], meta2["lon"], meta2["time_min"]
    dt_min = abs(t2 - t1)
    dt_hours = dt_min / 60.0
    if dt_hours < 1e-3:
        return 0.0
    dist_km = haversine_km(lat1, lon1, lat2, lon2)
    speed = dist_km / dt_hours
    if speed <= speed_limit:
        return 0.0
    elif speed >= max_speed:
        return 1.0
    else:
        return (speed - speed_limit) / (max_speed - speed_limit)


# 3. LOAD MODELS (CACHED)

@st.cache_resource
def load_models():
    if not os.path.exists(YOLO_MODEL_PATH):
        st.error(f"YOLO weights '{YOLO_MODEL_PATH}' not found in the app folder.")
        st.stop()

    yolo_model = YOLO(YOLO_MODEL_PATH)
    ocr_reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())

    weights = ResNet50_Weights.DEFAULT
    resnet = resnet50(weights=weights).to(DEVICE)
    resnet.eval()
    feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])

    embed_transform = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225])
    ])

    return yolo_model, ocr_reader, feature_extractor, embed_transform

yolo_model, ocr_reader, feature_extractor, embed_transform = load_models()

def get_vehicle_embedding(img_bgr: np.ndarray) -> np.ndarray:
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)
    x = embed_transform(pil_img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        feat = feature_extractor(x)
    vec = feat.view(feat.size(0), -1).cpu().numpy()[0]
    norm = np.linalg.norm(vec)
    if norm > 0:
        vec = vec / norm
    return vec


# 4. CORE PIPELINE FOR A SINGLE IMAGE

def process_single_image(file_bytes) -> dict:
    file_array = np.frombuffer(file_bytes, np.uint8)
    img_bgr = cv2.imdecode(file_array, cv2.IMREAD_COLOR)
    if img_bgr is None:
        return None

    results = yolo_model(img_bgr)[0]
    if results.boxes is None or len(results.boxes) == 0:
        return None

    boxes = results.boxes
    cls = boxes.cls.cpu().numpy().astype(int)
    conf = boxes.conf.cpu().numpy()

    PLATE_CLASS_ID = 0
    conf_thresh = 0.25
    plate_indices = [i for i, c in enumerate(cls) if c == PLATE_CLASS_ID and conf[i] >= conf_thresh]
    if not plate_indices:
        return None

    best_idx = plate_indices[np.argmax([conf[i] for i in plate_indices])]
    x1, y1, x2, y2 = boxes.xyxy[best_idx].cpu().numpy().astype(int)
    plate_conf = float(conf[best_idx])

    h, w = img_bgr.shape[:2]
    x1 = max(0, min(x1, w-1))
    x2 = max(0, min(x2, w))
    y1 = max(0, min(y1, h-1))
    y2 = max(0, min(y2, h))

    plate_crop = img_bgr[y1:y2, x1:x2]
    if plate_crop.size == 0:
        return None

    ph, pw = plate_crop.shape[:2]
    x_start = int(0.1 * pw)
    x_end = int(0.9 * pw)
    central_crop = plate_crop[:, x_start:x_end]

    ocr_result = ocr_reader.readtext(central_crop)
    if len(ocr_result) == 0:
        return None

    best_ocr = max(ocr_result, key=lambda x: x[2])
    plate_text_raw = best_ocr[1]
    ocr_conf = float(best_ocr[2])
    plate_text = clean_plate_text(plate_text_raw)
    if len(plate_text) < 4:
        return None

    embedding = get_vehicle_embedding(img_bgr)
    lat, lon = generate_random_location_uk()
    t_min = generate_random_time_minutes()
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    return {
        "image_bgr": img_bgr,
        "image_rgb": img_rgb,
        "plate_bbox": (x1, y1, x2, y2),
        "plate_conf": plate_conf,
        "plate_text": plate_text,
        "ocr_conf": ocr_conf,
        "embedding": embedding,
        "lat": lat,
        "lon": lon,
        "time_min": t_min
    }

def compute_clone_scores(info1: dict, info2: dict):
    emb1 = info1["embedding"].reshape(1, -1)
    emb2 = info2["embedding"].reshape(1, -1)
    sim = float(cosine_similarity(emb1, emb2)[0, 0])

    visual_term = 1.0 - sim
    min_ocr_conf = min(info1["ocr_conf"], info2["ocr_conf"])
    ocr_uncertainty = 1.0 - min_ocr_conf
    temporal_score = temporal_anomaly_score(info1, info2)

    ALPHA_VISUAL = 0.6
    BETA_OCR = 0.2
    GAMMA_TEMPORAL = 0.2

    clone_score = (
        ALPHA_VISUAL * visual_term +
        BETA_OCR * ocr_uncertainty +
        GAMMA_TEMPORAL * temporal_score
    )
    clone_score = float(max(0.0, min(1.0, clone_score)))

    return {
        "similarity": sim,
        "visual_term": visual_term,
        "ocr_uncertainty": ocr_uncertainty,
        "temporal_score": temporal_score,
        "clone_score": clone_score
    }


# 5. STREAMLIT UI

st.title(" ANPR Clone & Anomaly Detection – Demo App")
st.write(
    "This app demonstrates the core ideas from my MSc dissertation:\n"
    "- YOLOv8 licence plate detection\n"
    "- OCR-based plate reading\n"
    "- Deep learning vehicle ReID (ResNet50 embeddings)\n"
    "- Synthetic spatio-temporal anomaly reasoning\n"
    "- Combined clone suspicion scoring"
)

mode = st.sidebar.radio(
    "Select mode:",
    ["Single image inspection", "Clone suspicion between two images"]
)

st.sidebar.markdown("---")
st.sidebar.write(f"Device: `{DEVICE}`")
if DEVICE.type == "cuda":
    st.sidebar.success("Running on GPU")
else:
    st.sidebar.info("Running on CPU")

# Single image mode
if mode == "Single image inspection":
    st.header(" Single Image Inspection")
    uploaded_file = st.file_uploader(
        "Upload a vehicle image (JPG/PNG)",
        type=["jpg", "jpeg", "png"]
    )
    if uploaded_file is not None:
        info = process_single_image(uploaded_file.read())
        if info is None:
            st.error("I could not detect a valid plate in this image.")
        else:
            x1, y1, x2, y2 = info["plate_bbox"]
            img_display = info["image_rgb"].copy()
            cv2.rectangle(img_display, (x1, y1), (x2, y2), (255, 0, 0), 2)

            col1, col2 = st.columns([2, 1])
            with col1:
                st.image(img_display, caption="Detected plate", use_column_width=True)
            with col2:
                st.markdown("**Detected plate details:**")
                st.write(f"- Plate text: `{info['plate_text']}`")
                st.write(f"- OCR confidence: `{info['ocr_conf']:.3f}`")
                st.write(f"- YOLO confidence: `{info['plate_conf']:.3f}`")
                st.write(f"- Synthetic location: `{info['lat']:.4f}, {info['lon']:.4f}`")
                st.write(f"- Synthetic time (min since midnight): `{info['time_min']:.1f}`")
            st.success("Single image analysis complete.")

# Clone suspicion mode
else:
    st.header(" Clone Suspicion Between Two Images")
    col_left, col_right = st.columns(2)
    with col_left:
        file1 = st.file_uploader(
            "Upload first image",
            type=["jpg", "jpeg", "png"],
            key="img1"
        )
    with col_right:
        file2 = st.file_uploader(
            "Upload second image",
            type=["jpg", "jpeg", "png"],
            key="img2"
        )

    if file1 is not None and file2 is not None:
        info1 = process_single_image(file1.read())
        info2 = process_single_image(file2.read())
        if info1 is None or info2 is None:
            st.error("I could not detect a valid plate in one or both images.")
        else:
            scores = compute_clone_scores(info1, info2)

            img1 = info1["image_rgb"].copy()
            img2 = info2["image_rgb"].copy()
            x1a, y1a, x2a, y2a = info1["plate_bbox"]
            x1b, y1b, x2b, y2b = info2["plate_bbox"]
            cv2.rectangle(img1, (x1a, y1a), (x2a, y2a), (255, 0, 0), 2)
            cv2.rectangle(img2, (x1b, y1b), (x2b, y2b), (255, 0, 0), 2)

            img_col1, img_col2 = st.columns(2)
            with img_col1:
                st.image(img1, caption=f"Image 1 – Plate: {info1['plate_text']}", use_column_width=True)
            with img_col2:
                st.image(img2, caption=f"Image 2 – Plate: {info2['plate_text']}", use_column_width=True)

            st.subheader("Clone suspicion analysis")
            st.write("**Plate comparison:**")
            st.write(f"- Plate 1: `{info1['plate_text']}` (OCR conf: {info1['ocr_conf']:.3f})")
            st.write(f"- Plate 2: `{info2['plate_text']}` (OCR conf: {info2['ocr_conf']:.3f})")

            st.write("**Visual similarity (ReID):**")
            st.write(f"- Cosine similarity: `{scores['similarity']:.3f}` (1.0 = same, 0 = very different)")

            st.write("**Temporal anomaly:**")
            st.write(f"- Location 1: `{info1['lat']:.4f}, {info1['lon']:.4f}` at t={info1['time_min']:.1f} min")
            st.write(f"- Location 2: `{info2['lat']:.4f}, {info2['lon']:.4f}` at t={info2['time_min']:.1f} min")
            st.write(f"- Temporal anomaly score: `{scores['temporal_score']:.3f}`")

            st.write("**Final clone suspicion score:**")
            st.markdown(
                f"**Clone score (0–1):** `{scores['clone_score']:.3f}`  \n"
                f"- Visual term: `{scores['visual_term']:.3f}`  \n"
                f"- OCR uncertainty: `{scores['ocr_uncertainty']:.3f}`  \n"
                f"- Temporal contribution: `{scores['temporal_score']:.3f}`"
            )

            if scores["clone_score"] >= 0.7:
                st.error("Interpretation: **High** suspicion of a cloned/anomalous plate.")
            elif scores["clone_score"] >= 0.4:
                st.warning("Interpretation: **Moderate** suspicion. Worth further investigation.")
            else:
                st.success("Interpretation: **Low** suspicion based on this model.")
    else:
        st.info("Please upload two images to compare.")